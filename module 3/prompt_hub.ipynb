{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to the Prompt Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect our application to LangSmith's Prompt Hub, which will allow us to test and iterate on our prompts within LangSmith, and pull our improvements directly into our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull a prompt from Prompt Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in a prompt from Prompt Hub by pasting in the code snippet from the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aniket\\Documents\\Clg\\LLM - part 2\\myllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "import os\n",
    "from langsmith import Client\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"pirate-friend\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we pulled - note that we did not get the model, so this is just a StructuredPrompt and not runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'pirate-friend', 'lc_hub_commit_hash': '536bdc12d2263899d05dd12becf7b9adae3a9f8fa518c79c36f3f34a397a38f9'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template=\"You are a pirate from the 1600's , you only speak {language}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extracts the answer', 'type': 'object', 'properties': {'answer': {'type': 'string', 'description': 'the  answer from the LLM to the user'}}, 'required': ['answer'], 'additionalProperties': False, 'strict': True}, structured_output_kwargs={})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now let's hydrate our prompt by calling .invoke() with our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You are a pirate from the 1600's , you only speak Spanish\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Are you a captain yet?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\": \"Are you a captain yet?\", \"language\": \"Spanish\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's pass those messages to OpenAI and see what we get back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQGtwswezdejZImQraVlcAbRQ3Lfw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='¡Ahoy! No, aún no soy capitán, pero estoy en el camino de convertirme en uno. La vida en el mar es dura, pero con valor y astucia, algún día seré el capitán de mi propio barco. ¿Y tú, qué buscas en el océano?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760377532, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=61, prompt_tokens=32, total_tokens=93, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### [Extra: LangChain Only] Pulling down the Model Configuration\n",
    "\n",
    "We can also pull down the saved model configuration as a LangChain RunnableBinding when we use `include_model=True`. This allows us to run our prompt template directly with the saved model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out your prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.invoke({\"question\": \"Are you a captain yet?\", \"language\": \"Spanish\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull down a specific commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull down a specific commit from the Prompt Hub by pasting in the code snippet from the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"pirate-friend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this commit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQGzhdNWnpafj2GXj9R0meLtiahhS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Ahoy, matey! In the year 2500, the world be a wild blend of advanced technology and remnants of the past. The seas are still vast, but now they be filled with floating cities and mega-structures, where folk live atop the waters, and airships sail the skies like the galleons of old. \\n\\nEnvironmental challenges have shaped the world; climate change has led to rising oceans, reshaping coastlines and forcing many to adapt. Many areas are now lush with bioengineered flora and fauna designed to survive in altered conditions.\\n\\nThe digital realm is intertwined with reality, where virtual experiences blend with the physical world. Pirates like me navigate not just the waters, but also the vast networks of cyberspace, seeking treasure in both data and gold!\\n\\nThe law of the sea still exists, but it’s more about who can outsmart the systems of the mega-corporations and interstellar alliances than simple sword fights. It be a place of intrigue, adventure, and danger, where every horizon promises new treasures and rivalries. So, hoist the sails, for the future be full of promise and peril! Arrr!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760377889, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=232, prompt_tokens=32, total_tokens=264, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily update your prompts in the hub programmatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-rag-prompt/75567b82?organizationId=b3cf18a4-4e38-4c04-bff3-e0df17ce5621'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client=Client()\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "client.push_prompt(\"french-rag-prompt\", object=french_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also push a prompt as a RunnableSequence of a prompt and a model. This is useful for storing the model configuration you want to use with this prompt. The provider must be supported by the LangSmith playground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-runnable-sequence/f1499fb1?organizationId=b3cf18a4-4e38-4c04-bff3-e0df17ce5621'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client=Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "chain = french_prompt_template | model\n",
    "client.push_prompt(\"french-runnable-sequence\", object=chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my tweakings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"my_promt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQH5fm7UxNGEVEeSs0xM41mjjbfqF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Clearing an entrance exam requires a combination of effective preparation, time management, and strategic studying. Here are some steps you can follow to increase your chances of success:\\n\\n1. **Understand the Exam Format**: Familiarize yourself with the structure of the exam, including the types of questions, marking scheme, and time limits.\\n\\n2. **Gather Study Materials**: Collect textbooks, past papers, study guides, and online resources that are relevant to the exam. Ensure that you have the latest and most relevant materials.\\n\\n3. **Create a Study Plan**: Develop a realistic study schedule that covers all the topics you need to study. Break down your syllabus into manageable sections and allocate time for each.\\n\\n4. **Focus on the Basics**: Ensure you have a strong grasp of the fundamental concepts before diving into advanced topics. This foundation will help you tackle more complex problems later on.\\n\\n5. **Practice Regularly**: Solve previous years' question papers and take mock tests. This will help you familiarize yourself with the exam format and improve your time management skills.\\n\\n6. **Analyze Your Performance**: After practicing, review your answers to understand where you went wrong. Focus on correcting your mistakes and reinforcing your understanding of topics you find challenging.\\n\\n7. **Join Study Groups**: Collaborating with peers can enhance your understanding. Discussing topics with others can provide new insights and make studying more enjoyable.\\n\\n8. **Stay Healthy**: Take care of your physical and mental health. Ensure you get enough sleep, eat well, and take breaks during study sessions to avoid burnout.\\n\\n9. **Stay Positive and Manage Stress**: Develop a positive mindset and use relaxation techniques to manage exam stress. Visualization and deep-breathing exercises can be effective.\\n\\n10. **Reach Out for Help**: If you’re struggling with particular subjects, don’t hesitate to reach out to teachers, tutors, or online platforms for assistance.\\n\\n11. **Review Regularly**: Periodically review what you've studied to reinforce your memory and retention of the material.\\n\\n12. **Stay Informed**: Keep an eye on any announcements related to the exam, such as changes in format or important dates.\\n\\nRemember, consistency is key. Study regularly and allow yourself adequate time to cover all necessary material before the exam day. Good luck!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760378259, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=462, prompt_tokens=26, total_tokens=488, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"how to clear an enterance exam\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"my_promt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQH7bVSVNF9F9drTcveeljNOObgBs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Helping a student prepare for an entrance exam requires a structured approach and supportive guidance. Here are some effective strategies you can employ:\\n\\n1. **Understand the Exam Format**:\\n   - Familiarize the student with the exam structure, types of questions (multiple-choice, essay, etc.), subjects involved, and scoring methodology.\\n\\n2. **Conduct a Diagnostic Assessment**:\\n   - Assess the student's current knowledge and skills. Identify their strengths and weaknesses in the subjects that will be tested.\\n\\n3. **Create a Study Plan**:\\n   - Develop a tailored study schedule that includes regular study sessions, breaks, and time for review. Ensure it allocates time for each subject area based on the student's needs.\\n\\n4. **Gather Study Materials**:\\n   - Provide access to high-quality study resources such as textbooks, online courses, practice exams, and guides specific to the entrance exam.\\n\\n5. **Practice Regularly**:\\n   - Encourage the student to take full-length practice tests under timed conditions. This will help them get used to the pressure of the exam environment.\\n\\n6. **Teach Test-Taking Strategies**:\\n   - Share effective strategies for tackling different types of questions, managing time during the exam, and eliminating incorrect answer choices.\\n\\n7. **Review and Analyze Mistakes**:\\n   - After practice tests, review incorrect answers together. Discuss why the student made certain mistakes and how to avoid them in the future.\\n\\n8. **Strengthen Weak Areas**:\\n   - Focus on areas where the student struggles the most. Use targeted exercises to improve these skills.\\n\\n9. **Encourage a Growth Mindset**:\\n   - Motivate the student by emphasizing progress and effort rather than perfection. Remind them that improvement is possible with perseverance.\\n\\n10. **Incorporate Active Learning Techniques**:\\n    - Encourage methods like summarizing information, teaching concepts to others, and using flashcards to reinforce retention.\\n\\n11. **Foster a Healthy Study Environment**:\\n    - Ensure the student studies in a distraction-free environment. Encourage good habits like maintaining a balanced diet, getting enough sleep, and taking regular breaks to avoid burnout.\\n\\n12. **Simulate Real Exam Conditions**:\\n    - Before the actual exam, conduct mock exams to help the student practice in an environment that mimics the real testing situation.\\n\\n13. **Provide Emotional Support**:\\n    - Remind the student that it’s normal to feel anxious. Teach them relaxation techniques such as deep breathing exercises or mindfulness to manage stress.\\n\\n14. **Encourage Consistent Review**:\\n    - Regularly revisit material to reinforce learning. Spaced repetition is effective for long-term retention.\\n\\n15. **Stay Positive and Encourage Resilience**:\\n    - Celebrate small wins and progress, and help the student stay focused on their goals.\\n\\nBy following these strategies, you're not just helping the student prepare for an entrance exam but also teaching them valuable skills for academic success in the future.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760378379, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=585, prompt_tokens=26, total_tokens=611, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"how to make a student clear an enterance exam\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
