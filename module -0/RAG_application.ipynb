{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f686e698-fd2d-40a5-96c9-652b6d054bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71aec4e-ea0b-44f6-b94e-77c9d03c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import init_chat_model\n",
    "#model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8a22bb-ddfe-4a0e-950b-5cefe64083bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30850651-e47a-498c-9a8a-baeffc40e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-huggingface sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b695739f-388b-4d27-bd57-974aaba36f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aniket\\Documents\\Clg\\LLM - part 2\\myllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"groq\"\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\" \n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize Groq client\n",
    "llm = ChatGroq(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": RAG_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"}\n",
    "    ]\n",
    "    return call_groq(messages)\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_groq(messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0) -> str:\n",
    "    return llm.invoke(messages)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b42c-da91-43df-9ee0-2e871570d1ba",
   "metadata": {},
   "source": [
    "question = \"What is LangSmith used for?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"website\": \"www.google.com\"}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbfb7a9-1c8c-4159-9aa8-3289717f750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question: str):\n",
    "    return langsmith_rag(question, langsmith_extra={\"metadata\": {\"website\": \"www.google.com\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d291c7-3a1b-4d1d-be2f-0386bb97904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the current number of ODI centuries Virat Kohli has. The provided context does not contain information about Virat Kohli's cricket statistics.\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"how many odi centuries does virat kohli have ? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb6acb-d430-436c-bda4-452da9a2083f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "here we can see it does not work when asked an external question , and only answers the questions which can be answers based on the langsmith document. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae25222-bf8a-4ad0-9977-86e9280784e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is better than other frameworks because it is framework agnostic, allowing it to be used with or without LangChain's open source frameworks. This flexibility, combined with its ability to monitor and evaluate applications, enables developers to ship quickly and with confidence. Additionally, LangSmith's simple data format makes it easy to export and import trace data.\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"how is langsmith better than other frameworks ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf55a70-eec7-4966-a191-36be16df7adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
